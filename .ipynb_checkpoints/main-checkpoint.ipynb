{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607f522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle, time, math, random\n",
    "import tqdm.notebook as tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from Trading_functions import * # where required functions defined\n",
    "\n",
    "# data load - cannot upload on github, so I made a example df. \n",
    "# with open('./close_df.pkl', 'rb') as f:\n",
    "#     close_df = pickle.load(f)\n",
    "# with open('./volume_df.pkl', 'rb') as f:\n",
    "#     volume_df = pickle.load(f)\n",
    "# with open('./acml_df.pkl', 'rb') as f:\n",
    "#     acml_df = pickle.load(f)\n",
    "# with open('./low_df.pkl', 'rb') as f:\n",
    "#     low_df = pickle.load(f)\n",
    "# with open('./high_df.pkl', 'rb') as f:\n",
    "#     high_df = pickle.load(f)\n",
    "# with open('./open_df.pkl', 'rb') as f:\n",
    "#     open_df = pickle.load(f)\n",
    "# with open('./return_df.pkl', 'rb') as f:\n",
    "#     return_df = pickle.load(f)\n",
    "\n",
    "with open('df_index.pkl', 'rb') as f:\n",
    "    df_index = pickle.load(f)\n",
    "with open('df_columns.pkl', 'rb') as f:\n",
    "    df_columns = pickle.load(f)\n",
    "    \n",
    "example_df = pd.DataFrame([], index = df_index, columns = df_columns) # all None data. \n",
    "\n",
    "# id_set\n",
    "id_set = ['stck_clpr', 'stck_oprc', 'stck_hgpr', 'stck_lwpr', 'acml_tr_pbmn']\n",
    "\n",
    "# preprocess return data\n",
    "return_df =  ((return_df+1).applymap(winsorize) * (return_df-return_df+1)) # winsorize to crop extreme data\n",
    "return_df = ((acml_df==0)* (0.01)+ (acml_df>0)*return_df) # if not traded, give -99%\n",
    "return_df = return_df.replace([np.inf, -np.inf], np.nan) # inf to nan\n",
    "return_df[(close_df.notna().shift(1).fillna(False) * close_df.isna())] = 0.01 # if delisted, give -99%\n",
    "\n",
    "# mask on\n",
    "mask = (acml_df ==0).replace(True, np.nan).replace(False, 1)\n",
    "close_df *= mask\n",
    "volume_df *= mask\n",
    "open_df *= mask\n",
    "high_df *= mask\n",
    "low_df *= mask\n",
    "acml_df *= mask\n",
    "\n",
    "# additional mask for enough volume\n",
    "new_mask = volume_df.rolling(5, min_periods =1).min() > 10**7 * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b8064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_one(original, delete, change):\n",
    "    rand_num = len(original.split(delete))-1\n",
    "    rand_index = int(random.random()*rand_num)\n",
    "    split = original.split(delete)\n",
    "    split[rand_index] += (change + split[rand_index+1])\n",
    "    del split[rand_index+1]\n",
    "    return delete.join(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc80549",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GA_Generator(GraphGenerator):\n",
    "    def __init__(self, id_set, dic_operator):\n",
    "        super().__init__(id_set, dic_operator)\n",
    "    \n",
    "    def random_expression(self, depth, max_depth):\n",
    "        rand_value = random.random()\n",
    "        if depth ==0:\n",
    "            if random.random() < 1/3:\n",
    "                depth +=1\n",
    "                return 'BIGGER DOUBLE' + '(' + self.random_expression(depth, max_depth) + ',' + self.random_expression(depth, max_depth) + ')'\n",
    "            else:\n",
    "                depth +=1\n",
    "                return np.random.choice(['BIGGER 0', 'BIGGER 1'], p=[0.5, 0.5]) + '(' + self.random_expression(depth, max_depth) + ')'\n",
    "        if rand_value < depth/max_depth:\n",
    "            rand_ind = int(random.random()*len(self.id_set))\n",
    "            return 'GET' + '('+ self.id_set[rand_ind]+ ')'\n",
    "        elif rand_value < 1 - depth/(max_depth):\n",
    "            rand_ind = int(random.random()*len(self.p_modification))\n",
    "            depth +=1\n",
    "            return np.random.choice(list(self.dic_modification.keys()), p=self.p_modification) + '(' + self.random_expression(depth, max_depth) + ')'\n",
    "        else:\n",
    "            rand_ind = int(random.random()*len(self.p_combination))\n",
    "            depth +=1\n",
    "            return np.random.choice(list(self.dic_combination.keys()), p=self.p_combination) + '(' + self.random_expression(depth, max_depth) + ',' + self.random_expression(depth, max_depth) + ')'\n",
    "        \n",
    "    def calculate_depth(self, expression):\n",
    "        operation = expression.split('(')[0]\n",
    "        if operation in self.dic_imputer.keys():\n",
    "            return 1\n",
    "        elif operation in self.dic_modification.keys():\n",
    "            bracket_1 = expression.find('(')\n",
    "            bracket_2 = expression[::-1].find(')')\n",
    "            return self.calculate_depth(expression[bracket_1+1:len(expression)-bracket_2-1]) + 1\n",
    "        elif operation in self.dic_combination.keys():\n",
    "            counter = 0\n",
    "            bracket_1 = expression.find('(')\n",
    "            bracket_2 = expression[::-1].find(')')\n",
    "            inner = expression[bracket_1+1:len(expression)-bracket_2-1]\n",
    "            for i in range(len(inner)):\n",
    "                if (counter == 0) and inner[i] == ',':\n",
    "                    first = inner[:i]\n",
    "                    second = inner[i+1:]\n",
    "                elif inner[i] == '(':\n",
    "                    counter +=1\n",
    "                elif inner[i] == ')':\n",
    "                    counter -=1\n",
    "            return max(self.calculate_depth(first), self.calculate_depth(second)) + 1\n",
    "        elif operation == 'BIGGER DOUBLE':\n",
    "            counter = 0\n",
    "            bracket_1 = expression.find('(')\n",
    "            bracket_2 = expression[::-1].find(')')\n",
    "            inner = expression[bracket_1+1:len(expression)-bracket_2-1]\n",
    "            for i in range(len(inner)):\n",
    "                if (counter == 0) and inner[i] == ',':\n",
    "                    first = inner[:i]\n",
    "                    second = inner[i+1:]\n",
    "                elif inner[i] == '(':\n",
    "                    counter +=1\n",
    "                elif inner[i] == ')':\n",
    "                    counter -=1\n",
    "            return max(self.calculate_depth(first), self.calculate_depth(second)) + 1\n",
    "        else:\n",
    "            bracket_1 = expression.find('(')\n",
    "            bracket_2 = expression[::-1].find(')')\n",
    "            return self.calculate_depth(expression[bracket_1+1:len(expression)-bracket_2-1]) + 1\n",
    "        \n",
    "    def peel_expression(self, expression):\n",
    "        operation = expression.split('(')[0]\n",
    "        if operation in self.dic_imputer.keys():\n",
    "            return expression\n",
    "        elif operation in self.dic_modification.keys():\n",
    "            bracket_1 = expression.find('(')\n",
    "            bracket_2 = expression[::-1].find(')')\n",
    "            return expression[bracket_1+1:len(expression)-bracket_2-1]\n",
    "        elif operation in self.dic_combination.keys():\n",
    "            counter = 0\n",
    "            bracket_1 = expression.find('(')\n",
    "            bracket_2 = expression[::-1].find(')')\n",
    "            inner = expression[bracket_1+1:len(expression)-bracket_2-1]\n",
    "            for i in range(len(inner)):\n",
    "                if (counter == 0) and inner[i] == ',':\n",
    "                    first = inner[:i]\n",
    "                    second = inner[i+1:]\n",
    "                elif inner[i] == '(':\n",
    "                    counter +=1\n",
    "                elif inner[i] == ')':\n",
    "                    counter -=1\n",
    "            if random.random() < 0.5:\n",
    "                return first\n",
    "            else:\n",
    "                return second\n",
    "        elif operation == 'BIGGER DOUBLE':\n",
    "            counter = 0\n",
    "            bracket_1 = expression.find('(')\n",
    "            bracket_2 = expression[::-1].find(')')\n",
    "            inner = expression[bracket_1+1:len(expression)-bracket_2-1]\n",
    "            for i in range(len(inner)):\n",
    "                if (counter == 0) and inner[i] == ',':\n",
    "                    first = inner[:i]\n",
    "                    second = inner[i+1:]\n",
    "                elif inner[i] == '(':\n",
    "                    counter +=1\n",
    "                elif inner[i] == ')':\n",
    "                    counter -=1\n",
    "            if random.random() < 0.5:\n",
    "                return first\n",
    "            else:\n",
    "                return second\n",
    "        else:\n",
    "            bracket_1 = expression.find('(')\n",
    "            bracket_2 = expression[::-1].find(')')\n",
    "            return expression[bracket_1+1:len(expression)-bracket_2-1]\n",
    "        \n",
    "    def peel_iteration(self, expression, iteration):\n",
    "        for i in range(iteration):\n",
    "            expression = self.peel_expression(expression)\n",
    "        return expression\n",
    "    \n",
    "    def mix(self, expression1, expression2):\n",
    "        depth1 = self.calculate_depth(expression1)\n",
    "        depth2 = self.calculate_depth(expression2)\n",
    "        max_depth = min(depth1, depth2) - 2 # minimum 1 \n",
    "        change_depth = int(random.random()*max_depth) + 1\n",
    "        injected = expression1\n",
    "        ed_depth = depth1\n",
    "        injector = expression2\n",
    "        or_depth = depth2\n",
    "        if random.random()< 0.5:\n",
    "            injected, injector = injector, injected\n",
    "            ed_depth, or_depth = or_depth, ed_depth\n",
    "        delete_expression = self.peel_iteration(injected, ed_depth - change_depth)\n",
    "        injected_expression = self.peel_iteration(injector, or_depth - change_depth)\n",
    "        return replace_one(injected, delete_expression, injected_expression)\n",
    "    \n",
    "    def mutate(self, expression):\n",
    "        depth = self.calculate_depth(expression) - 2\n",
    "        change_depth = int(random.random()*depth) + 1\n",
    "        delete_expression = self.peel_iteration(expression, change_depth)\n",
    "        mutation = self.random_expression(1, depth+2 - change_depth)\n",
    "        return replace_one(expression, delete_expression, mutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0055b3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GA_child(object):\n",
    "    def __init__(self):\n",
    "        self.filters = []\n",
    "        self.datas = []\n",
    "        self.data = None\n",
    "        \n",
    "    def add(self, graph):\n",
    "        self.filters.append(graph.expression)\n",
    "        self.datas.append(graph.data)\n",
    "        if type(self.data) == type(None):\n",
    "            self.data = graph.data\n",
    "        else:\n",
    "            self.data *= graph.data\n",
    "        self.data *= new_mask\n",
    "        \n",
    "    def delete(self):\n",
    "        index = int(random.random() * len(self.filters))\n",
    "        del self.filters[index]\n",
    "        del self.datas[index]\n",
    "        \n",
    "    def get_one(self):\n",
    "        index = int(random.random() * len(self.filters))\n",
    "        return self.filters[index], index\n",
    "    \n",
    "    def update(self):\n",
    "        self.data = self.datas[0]\n",
    "        if len(self.datas)>1:\n",
    "            for data in self.datas[1:]:\n",
    "                self.data *= data\n",
    "        self.data *= new_mask\n",
    "    \n",
    "    def get_case_data(self, engine, full, training):\n",
    "        datas = []\n",
    "        for expression in self.filters:\n",
    "            datas.append(engine.expression_to_graph(expression, full, training).data)\n",
    "        data = datas[0]\n",
    "        if len(datas)>1:\n",
    "            for data_2 in datas[1:]:\n",
    "                data *= data_2\n",
    "        if training=='training':\n",
    "            case_mask = new_mask.loc['20060101':'20170101']\n",
    "        elif training == 'validation':\n",
    "            case_mask = new_mask.loc['20170101':'20210101']\n",
    "        else:\n",
    "            case_mask = new_mask.loc['20210101':]\n",
    "        return data * case_mask\n",
    "    \n",
    "    def addition(self, child):\n",
    "        if len(self.filters) + len(child.filters) <= 3:\n",
    "            return self.filters + child.filters, self.datas + child.datas\n",
    "        else:\n",
    "            new_filters = []\n",
    "            new_datas = []\n",
    "            if len(self.filters) > len(child.filters):\n",
    "                index = random.sample(list(range(len(self.filters))), 2)\n",
    "                for i in index:\n",
    "                    new_filters.append(self.filters[i])\n",
    "                    new_datas.append(self.datas[i])\n",
    "                    \n",
    "                index = random.sample(list(range(len(child.filters))), 1)\n",
    "                new_filters.append(child.filters[index[0]])\n",
    "                new_datas.append(child.datas[index[0]])\n",
    "                return new_filters, new_datas\n",
    "            else:\n",
    "                index = random.sample(list(range(len(self.filters))), 1)\n",
    "                new_filters.append(self.filters[index[0]])\n",
    "                new_datas.append(self.datas[index[0]])\n",
    "                \n",
    "                index = random.sample(list(range(len(child.filters))), 2)\n",
    "                for i in index:\n",
    "                    new_filters.append(child.filters[i])\n",
    "                    new_datas.append(child.datas[i])\n",
    "                return new_filters, new_datas\n",
    "            \n",
    "    def restore(self, filters):\n",
    "        for exp in filters:\n",
    "            self.add(engine.expression_to_graph(exp, True, 'training'))\n",
    "\n",
    "def health_check(graph):\n",
    "    graph.data *= new_mask\n",
    "    if ((graph.data.sum(axis=1)/close_df.notna().sum(axis=1)).mean(0) > 0.4) or ((graph.data.sum(axis=1)/close_df.notna().sum(axis=1)).mean(0) < 0.1):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def cagr(cash_hist):\n",
    "    return (cash_hist[-1]/cash_hist[0])**(252/len(cash_hist))-1\n",
    "\n",
    "def stdv(returns):\n",
    "    return np.std(returns)*math.sqrt(252)\n",
    "\n",
    "def sharpe(returns):\n",
    "    return cagr(returns.cumprod())/stdv(returns)\n",
    "\n",
    "def transaction_cost(weight):\n",
    "    cost = (((weight - weight.shift(-1)) > 0).astype(float) * (weight-weight.shift(-1))).sum(1) *0.0031\n",
    "    return (1-cost).shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609850b1",
   "metadata": {},
   "source": [
    "# GA run\n",
    "\n",
    "children num : Pool size (Trade-off between performance and time)  \n",
    "depth : expression tree size (Representation power)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143501b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "children = []\n",
    "engine = GA_Generator(id_set, dic_operator)\n",
    "\n",
    "start_time = time.time()\n",
    "# Make first Generation born\n",
    "child_num = 30\n",
    "child_num2 = child_num\n",
    "tree_depth = 3\n",
    "high_val = 0\n",
    "count = 0\n",
    "\n",
    "print('generation 0')\n",
    "while child_num > 0:\n",
    "    graph = engine.expression_to_graph(engine.random_expression(0,tree_depth), True, 'training')\n",
    "    if health_check(graph):\n",
    "        child = GA_child()\n",
    "        child.add(graph)\n",
    "        children.append(child)\n",
    "        child_num -=1\n",
    "    else:\n",
    "        pass\n",
    "child_num = child_num2\n",
    "\n",
    "print('breeding completed')\n",
    "\n",
    "\n",
    "print('Evolution starts')\n",
    "# Start Evolution\n",
    "for gen in range(100):\n",
    "    miss_trial = 0\n",
    "\n",
    "    # calculate\n",
    "    cagr_list = []\n",
    "    for child in children:\n",
    "        weight = ((1/child.data.sum(axis=1)).replace([np.inf, -np.inf], np.nan).tolist()* child.data.T).T.shift(1)\n",
    "        weight = weight.applymap(lambda x: 0.1 if x > 0.1 else x) # Maximum weight 0.1\n",
    "        cost_discount = transaction_cost(weight)\n",
    "        for_std = ((weight * (return_df.loc['20060101':'20170101'])).sum(axis=1)*cost_discount) + (1 - weight.sum(1))\n",
    "        cagr_list.append(sharpe(for_std.iloc[1:]))\n",
    "\n",
    "\n",
    "    # find Dominants\n",
    "    dominant_num = int(child_num * 0.2)\n",
    "    dom_index = np.argsort(cagr_list)[-dominant_num:]\n",
    "    dominants = []\n",
    "    for index in dom_index:\n",
    "        dominants.append(children[index])\n",
    "    print(gen, 'th generation dominant mean score:', np.mean(np.array(cagr_list)[dom_index]))\n",
    "\n",
    "    # get Validation performace\n",
    "    cagr_list_val = []\n",
    "    for dominant in dominants:\n",
    "        temp_data = dominant.get_case_data(engine, True, 'validation')\n",
    "        weight = ((1/temp_data.sum(axis=1)).replace([np.inf, -np.inf], np.nan).tolist()* temp_data.T).T.shift(1)\n",
    "        weight = weight.applymap(lambda x: 0.1 if x > 0.1 else x)\n",
    "        cost_discount = transaction_cost(weight)\n",
    "        for_std = ((weight * (return_df.loc['20170101':'20210101'])).sum(axis=1)*cost_discount) + (1-weight.sum(1))\n",
    "        cagr_list_val.append(sharpe(for_std.iloc[1:]))\n",
    "    print(gen, 'th generation dominant mean validation score:', np.mean(cagr_list_val))\n",
    "\n",
    "\n",
    "    if np.mean(cagr_list_val)> high_val:\n",
    "        high_val = np.mean(cagr_list_val)\n",
    "    \n",
    "    # dump\n",
    "    with open('high_val_depth_'+str(count)+'.pkl', 'wb') as f:\n",
    "        pickle.dump([dominant.filters for dominant in dominants], f)\n",
    "\n",
    "    # make mix\n",
    "    mix_num = int(child_num * 0.07)\n",
    "    mix_list = []\n",
    "    trial = 0\n",
    "    while (mix_num > 0) and trial < 100:\n",
    "        ind1, ind2 = int(random.random()*dominant_num), int(random.random()*dominant_num)\n",
    "        exp1, child_ind1 = dominants[ind1].get_one()\n",
    "        exp2, child_ind2 = dominants[ind2].get_one()\n",
    "        mix_gen = engine.mix(exp1, exp2)\n",
    "        graph = engine.expression_to_graph(mix_gen, True, 'training')\n",
    "        new_gen = copy.deepcopy(dominants[ind1])\n",
    "        new_gen.filters[child_ind1] = mix_gen\n",
    "        new_gen.datas[child_ind1] = graph.data\n",
    "        new_gen.update()\n",
    "        if health_check(new_gen):\n",
    "            mix_list.append(new_gen)\n",
    "            mix_num -=1\n",
    "        else:\n",
    "            trial += 1\n",
    "    if trial == 100:\n",
    "        miss_trial += mix_num\n",
    "\n",
    "    mutate_num = int(child_num * 0.1)\n",
    "    mutate_list = []\n",
    "    trial = 0\n",
    "    while (mutate_num > 0) and trial < 100:\n",
    "        ind = int(random.random()*dominant_num)\n",
    "        exp, child_ind = dominants[ind].get_one()\n",
    "        mutate_gen = engine.mutate(exp)\n",
    "        graph = engine.expression_to_graph(mutate_gen, True, 'training')\n",
    "        new_gen = copy.deepcopy(dominants[ind])\n",
    "        new_gen.filters[child_ind] = mutate_gen\n",
    "        new_gen.datas[child_ind] = graph.data\n",
    "        new_gen.update()\n",
    "        if health_check(new_gen):\n",
    "            mutate_list.append(new_gen)\n",
    "            mutate_num -=1\n",
    "        else:\n",
    "            trial +=1\n",
    "    if trial == 100:\n",
    "        miss_trial += mutate_num\n",
    "\n",
    "    # make addition\n",
    "    addition_num = int(child_num * 0.07)\n",
    "    addition_list = []\n",
    "    trial = 0\n",
    "    while (addition_num > 0) and (trial < 100):\n",
    "        ind1, ind2 = int(random.random()*dominant_num), int(random.random()*dominant_num)\n",
    "        new_filters, new_datas = dominants[ind1].addition(dominants[ind2])\n",
    "        new_gen = GA_child()\n",
    "        new_gen.filters = new_filters\n",
    "        new_gen.datas = new_datas\n",
    "        new_gen.update()\n",
    "        if health_check(new_gen):\n",
    "            addition_list.append(new_gen)\n",
    "            addition_num -=1\n",
    "        else:\n",
    "            trial+=1\n",
    "    if trial == 100:\n",
    "        miss_trial += addition_num\n",
    "\n",
    "    # make new candidates\n",
    "    new_num = int(child_num * 0.58) + miss_trial\n",
    "    new_list = []\n",
    "    while new_num > 0:\n",
    "        graph = engine.expression_to_graph(engine.random_expression(0,tree_depth), True, 'training')\n",
    "        if health_check(graph):\n",
    "            new_child = GA_child()\n",
    "            new_child.add(graph)\n",
    "            new_list.append(new_child)\n",
    "            new_num -=1\n",
    "        else:\n",
    "            pass\n",
    "    children = dominants + mix_list + mutate_list + addition_list + new_list\n",
    "    resets = []\n",
    "    for i in range(len(children)):\n",
    "        test_child = GA_child()\n",
    "        test_child.restore(children[i].filters)\n",
    "        resets.append(test_child)\n",
    "    children = resets\n",
    "    count+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
